#!/usr/local/bin/python3

"""
http://blog.miguelgrinberg.com/post/designing-a-restful-api-using-flask-restful
http://flask.pocoo.org/docs/quickstart/
http://flask-restful.readthedocs.org/en/latest/

Computes the amount of $$ that can be withdrawn during retirement - using Monte-Carlo simulations
All inputs are within the program
A scenario includes a number of phases (e.g. working, semi-retirement, retirement)
Each phase has a portfolio allocation of asset types (stocks, bonds, etc), and a contribution (negative for withdrawal).
If the "ToCompute" flag is set in a phase, then the contribution (in this case withdrawal) will be computed by the MC simulations.
More that one phase can set ToCompute, but all these phases will share the same computed contribution
The MC simulations use the Historical mean,stddev for each asset class - and generate random rate of returns using a
normal distribution based on the mean/stddev of the given asset class
The simulations are run "NbRun" and the contribution amount is returned based on the confidence factor

IMPORTANT
1/ Make sure each process uses a known seed for random number generator
See: https://bbabenko.github.io/multiprocessing-and-seeded-RNGs/
2/ See use of partial

"""

# ToDo: Add Readme - including syntax for TOML file
# ToDo: add loop to find value for retirement_spend that meets goal and/or optimal asset allocation

import getopt
import logging
import sys, os
import traceback
import numpy as np
import pandas as pd
import collections
import datetime as dt
import montecarlo_utilities as mc_ut
import utilities as ut
import tomli
from pprint import pformat
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter
from matplotlib.backends.backend_pdf import PdfPages
from multiprocessing import Pool, set_start_method
from logger import logger
from configuration_manager_class import ConfigurationManager
from typing import List
# import itertools

# from multiprocessing import cpu_count
from functools import partial

# Configuration
plt.style.use("seaborn-v0_8-deep")
Debug = False
plot_flag = False
outf = None  # placeholder for global variable
BF_BDAY = '04/09/1958'
Max_run_to_save = 250  # Max number of runs for which we save assets at end of each run

"""
From: http://fc.standardandpoors.com/sites/client/generic/axa/axa4/Article.vm?topic=5991&siteContent=8088
Total Returns From 1926-2017*
     Stocks    Bonds    T-Bills
Annualized Return    10.2%    5.6%    3.5%
Best Year    60.0 (1935)    42.1 (1982)    14.0 (1981)
Worst Year    -41.1 (1931)    -12.2 (2009)    0.0 (1940)
Standard Deviation    18.7    7.7    0.9
"""
AssetClasses = collections.namedtuple(
    "AssetClasses", "Stocks Bonds TBills Cash"
)  # Immutable
historical_return_2017 = AssetClasses(
    Stocks=(10.20, 18.70), Bonds=(5.60, 7.70), TBills=(3.50, 0.90), Cash=(0.0, 0.0)
)
default_pfolio_alloc = AssetClasses(Stocks=0.75, Bonds=0.15, TBills=0.05, Cash=0.05)


class ArrayRandGen:
    def __init__(self, ages, stats):
        self.nb = ages[1] - ages[0] + 1
        self.mean = stats[0]
        self.stdv = stats[1]

    def __iter__(self):
        return self

    def __next__(self):
        # returns a list of nb random numbers based on mean and stddev
        # numbers are: 1 + random_number/100  (interest rates)
        yield [
            1 + 0.01 * np.random.normal(self.mean, self.stdv) for _ in range(self.nb)
        ]


class MonteCarloProcessor:
    """Main orchestrator class for MonteCarlo  processing with multiple processors.
    """

    def __init__(self, cmd_line: List[str]):
        self.prog_name = ut.get_prog_name()
        self.config_manager = ConfigurationManager(self.prog_name, cmd_line)
        self.config = self.config_manager.get_class_config(self.__class__.__name__)
        self.nb_cpu = self.config['nb_cpu']
        self.run_cnt = self.config['run_cnt']
        self.iter_cnt = self.config['iter_cnt']
        self.opt_type = self.config['opt_type']

    def _log_info_tick(self, msg: str, xtra_log_msg = None) -> None:
        """Log info and tick timer"""
        if xtra_log_msg is not None:
            logger.info(f"{msg}\n{xtra_log_msg}")
        else:
            logger.info(msg)
        self.config_manager._tick_timer(msg)
        return
    def run(self):
        pass

    def cleanup(self, processor_kill_flag: bool = False):
        pass



def mk_ror_df(gen_list, index, ages):
    """
    Generate a dataframe where columns are integers in range(start, end) - where the rates of return are 
    generated by the generators in gen_list
    :param gen_list: list of generators
    :param index: index of DF
    :param ages: 2-tuple with start and end age
    :return: pd.DataFrame with end-start columns
    """
    start = ages[0]
    end = ages[1]
    df = pd.DataFrame(
        data=None, index=index, columns=list(range(start, end + 1)), dtype=float
    )
    for idx, gener in zip(list(index), gen_list):
        # generator returns a 1-element list which contains the list of values
        df.loc[idx] = list(next(gener))[0]
    return df


def re_allocate(asset, alloc, re_alloc_error):
    """
    Re-allocate assets based on desired asset allocation "alloc" - when asset amounts are negative
    :param asset: Series of assets
    :param alloc: Target allocation
    :return: new values of asset
    """
    if all(asset >= 0.0):  # all good, all amounts are positive or zero
        return asset, alloc  # done
    if asset.sum() <= 0.0:  # Busted - sum of amounts are negative or 0 -> return all 0s
        return pd.Series(0, index=np.arange(len(asset))), alloc

    # Need to make adjustments
    n_asset = asset.copy(deep=True)
    n_alloc = alloc.copy(deep=True)
    # Need to iterate until all asset classes are positive or zero
    neg_flag = n_asset < 0.0
    while any(neg_flag):  # While one asset category is negative
        # Some = but not all - assets have negative amount
        to_re_allocate = n_asset[neg_flag].sum()  # sum of all negative amounts
        n_asset[neg_flag] = 0.0  # zero out assets that have no money
        n_alloc[neg_flag] = 0.0  # zero out allocation of asset that have no money
        tot = n_alloc.sum()  # will be < 1.0
        n_alloc = (n_alloc / tot)  # rebalance allocations for classes that have positive amount
        assert (abs(n_alloc.sum() - 1.0) < re_alloc_error),\
            "n_alloc adds up to {:,.4f} - not 1.0 - n_alloc:\n".format(n_alloc.sum()) + str(n_alloc)
        adjust = (n_alloc * to_re_allocate)  # distribute amount to re-allocate among assets still active
        n_asset += adjust
        neg_flag = (n_asset < 0.0)  # Re-test - some asset classes may have become negative after rebalancing
        if abs(asset.sum() - n_asset.sum()) > re_alloc_error:
            ut.print_out(outf,
                         "Asset {:,.4f} and re-allocated assets {:,.4f} don't add up - delta = {:,.8f}".format(asset.sum(),
                            n_asset.sum(), asset.sum() - n_asset.sum()))
    return n_asset, n_alloc


def run_mc_multi(init_asset, ror_stats, cashflow_ser, re_alloc_error, cnt, seed):
    """
    Run Montecarlo simulation
    :param init_asset: (N,) SERIES of assets allocated by asset class
    :param ror_stats: Namedstuple keyed by asset class name with 2-tuple values
    :param cashflow_ser: Series of yearly withdrawals [or income] for each consecutive age
    :param cnt: Nb of iterations to run the simulation
    :return: [N, cnt] DF with ending amount by asset class for each simulation run

    Each process must initialize randon number generator's seed
    https://bbabenko.github.io/multiprocessing-and-seeded-RNGs/
    """
    # print("run_mc_multi: pid: {}, cnt= {}, seed={}".format(os.getpid(), cnt, seed))
    np.random.seed(seed)
    age_col = list(cashflow_ser.index)
    ages = (int(age_col[0]), int(age_col[-1]))  # start and end age
    idx_name = init_asset.index
    ror_gen_list = [ArrayRandGen(ages, a) for a in ror_stats]  # List of generators
    # Create dataframe for results - rows are asset classes, columns are iterations
    asset_df = pd.DataFrame(index=idx_name, dtype=float)  # Empty DF with the right index
    # Compute initial asset allocation - and use it for rebalancing
    init_alloc = init_asset / init_asset.sum()
    busted_ages = []
    for itr in range(cnt):
        asset_tmp = init_asset.copy(deep=True)  # initialize
        wdrwl_alloc = init_alloc  # Initial allocation of withdrawals
        # Generate a new array of rate of returns for all ages and each asset class
        ror_df = mk_ror_df(ror_gen_list, idx_name, ages)
        for age in age_col:
            # Compute returns of existing assets and allocate year's withdrawal weighted to available assets
            asset_tmp = asset_tmp * ror_df[age] + wdrwl_alloc * cashflow_ser[age]
            if asset_tmp.sum() <= 0.0:  # Busted: no more money
                # logger.info('Busted! @iter: {:d} - age {:d}'.format(iter, int(age)))
                busted_ages += [age]
                break  # Stop iterating over age
            else:
                n_asset, wdrwl_alloc = re_allocate(asset_tmp, wdrwl_alloc, re_alloc_error)
                assert (
                    abs(asset_tmp.sum() - n_asset.sum()) < re_alloc_error
                ), "Asset {:,.4f} and re-allocated assets {:,.4f} don't add up - delta = {:,.8f}\n, iter={:d} - age={:d}".format(
                    asset_tmp.sum(), n_asset.sum(), asset_tmp.sum() - n_asset.sum(), itr, age,)
                asset_tmp = n_asset
        # asset_df[iter] = asset_tmp  # store final result of this simulation run
        asset_tmp.name = itr
        asset_df = pd.concat([asset_df, asset_tmp], axis=1)  # store final result of this simulation run
    return asset_df, busted_ages


def main(argv):
    global outf, plot_flag

    start_time = dt.datetime.now()
    prog_name = argv[0].lstrip("./").rstrip(".py")
    out_file = prog_name + "_out.txt"
    outf = open(out_file, "w")
    xl_file = prog_name + "_out.xlsx"
    toml_file = prog_name + ".toml"
    plot_file = prog_name + ".pdf"
    plt_file = PdfPages(plot_file)

    # logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    handler = logging.FileHandler(prog_name + ".log")
    handler.setLevel(logging.DEBUG)
    # create a logging format
    # formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    formatter = logging.Formatter("%(message)s")
    handler.setFormatter(formatter)
    # add the handlers to the logger
    logger.addHandler(handler)
    # create console handler and set level to debug
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(formatter)
    # add ch to logger
    logger.addHandler(ch)
    logger.debug("Start: {}\n".format(str(start_time)))
    logger.debug("Debug")

    # Read parameters from TOML file
    logger.info("Using TOML file: {}".format(toml_file))
    with open(toml_file, mode='rb') as f:
        in_data = tomli.load(f)
    logger.info("Parameters:")
    logger.info(pformat((in_data)))
    # Get other config data
    user_data = in_data["user_data"]
    target_end_funds = user_data["target_end_funds"]
    default_inflation_rate = user_data["default_inflation_rate"]
    target_success_rate = user_data["target_success_rate"]
    goals_file = user_data["goals_file"]
    Death_age = user_data["Death_age"]
    End_age = user_data["End_age"]
    default_values = in_data["default_values"]
    Funds_step = default_values["Funds_step"]
    Discret_step = default_values["Discret_step"]
    Success_threshold = default_values["Success_threshold"]
    Max_iter = default_values["Max_iter"]
    seed = default_values["seed"]
    re_alloc_error = default_values["re_alloc_error"]
    if not run_opt:  # Run count was Not overriden on command line
        run_cnt = default_values["run_cnt"]
    if not cpu_opt:  # CPU count was Not overriden on command line
        nb_cpu = default_values["nb_cpu"]
    pfolio_alloc = in_data["pfolio_alloc"]

    # Process the Goals file
    initial_goals_df = mc_ut.process_goals_file(goals_file, BF_BDAY, Death_age, End_age, default_inflation_rate)
    print(f"initial_goals_df:\n{initial_goals_df}")
    start_age = min(initial_goals_df['Start_age'])
    end_age = max(initial_goals_df['End_age'])
    age_lst = list(range(start_age, end_age + 1))  # include end_age

   # Create names for index and columns of dataframes
    index_name = list(pfolio_alloc.keys())
    # Make sure Portfolio Allocation adds up to 100% - if not resize
    if sum(pfolio_alloc.values()) != 1.0:  # Resize commmesurately
        resize = sum(pfolio_alloc.values())
        logger.info("Portfolio allocation is not 100%: {:,.2f} -> Resizing".format(100.0 * resize),)
        if resize == 0.0:  # problem
            logger.info("ERROR: Portfolio allocations are missing or equal to 0 - Stopping",)
            exit(-1)
        else:
            for k in pfolio_alloc.keys():
                pfolio_alloc[k] *= 1.0 / resize
    logger.info("Portfolio Allocations:\n" + pformat(pfolio_alloc))
    ror_stats = historical_return_2017

    start_funds = user_data["start_funds"]
    goals_df = initial_goals_df.copy(deep=True)
    discretionary_mult = 1.0
    not_success = True
    prev_iter_success = False  # does not matter
    iter_cnt = 0
    cashflow_df, cashflow_total_ser = ut.make_cashflow(goals_df)
    print(f"\ncashflow_df:\n{cashflow_df.head()}")
    # run MonteCarlo - Multi-processor mode
    pool = Pool(processes=nb_cpu)
    # partial “freezes” some the first arguments of run_mc_multi and appends values of run_cnt_list as it iterates
    # https://docs.python.org/3.6/library/functools.html
    # Generate the seeds for each process - for repeatability
    ns = int(run_cnt / nb_cpu)  # number of samples for each process
    run_cnt = nb_cpu * ns  # in case we have rounding above
    np.random.seed(seed)  # Set seed for repeatability
    seed_list = np.random.randint(1, pow(2, 32) - 1, size=nb_cpu)  # Generate random seeds for each process
    param_list = zip([ns] * nb_cpu, seed_list)  # [[ns, seed1], [ns, seed2], ...]

    while not_success and iter_cnt < Max_iter:

        # FIXME: move all this to the MonteCarloSimulation class



        # Adjust Start Assets based on new start_funds
        start_assets = pd.Series([start_funds * x for x in pfolio_alloc.values()], index=index_name)
        assets_df = pd.DataFrame(start_assets)
        assets_df.columns = [start_age]  # single value
        logger.info("Start Assets:\n" + str(assets_df))

        # ToDo Use chunksize
        result_obj = pool.starmap_async(
            partial(run_mc_multi, start_assets, ror_stats, cashflow_total_ser, re_alloc_error), param_list,)
        pool.close()
        pool.join()
        result_list = result_obj.get()
        result_asset = [x[0] for x in result_list]
        result_busted = [x[1] for x in result_list]
        # Flatten result_busted into a single list
        busted_age_lst = [x for y in result_busted for x in y]
        # Organize the busted ages
        busted_cnt = collections.Counter(busted_age_lst)
        busted_counter = {k: busted_cnt[k] for k in sorted(busted_cnt.keys())}
        assets_at_end = pd.concat(result_asset, axis=1, ignore_index=True)  # Merge into single DF
        print(f"col of assets_at_end: {assets_at_end.columns}")
        assets_at_end.loc["Total"] = assets_at_end.sum(axis=0)
        total_ser = assets_at_end.loc["Total"].copy(deep=True)  # so that we can sort
        total_ser.sort_values(inplace=True, ascending=True)
        total_ser.reset_index(inplace=True, drop=True)  # needed after sort
        nb_bust = sum([x for x in busted_counter.values()])

        # FIXME: approx end of ... move all this to the MonteCarloSimulation class


        
        logger.info("#1 Busted {:,d} times out of {:,d} -> {:.2f}%".format(
                nb_bust, run_cnt, 100.0 * nb_bust / run_cnt),)
        # Note that nb_bust and nb_success don't necessarily add up to 100% - 3rd category: 0< end_assets < target_end_funds
        success_rate = 100 * len(total_ser[total_ser >= target_end_funds]) / run_cnt
        success_fail = "Success" if success_rate >= target_success_rate else "Failure"
        success_string = f"{success_fail}: Start Funds: ${start_funds:,.0f} - Discretionary Mult: " \
                         f"{discretionary_mult:.3f} - " +\
                         f"Success rate: {success_rate}% vs target: {target_success_rate}%"
        logger.info(success_string)
        # Declare success if we are not optimizing or success rate is close to goal
        if abs(success_rate - target_success_rate) < Success_threshold or 'opt_type' not in locals():
            not_success = False  # i.e yes, success
        else:
            # Adjust based on optimization strategy
            this_iter_succcess = True if success_rate > target_success_rate else False
            if opt_type == 'start_funds':
                # Adjust starting funds and repeat
                increase_decrease = -1 if this_iter_succcess else 1  # add or substract funds?
                start_funds += increase_decrease * Funds_step
            elif opt_type == 'discretionary':
                if iter_cnt >= 1:  # see if we need to change the Step
                    if this_iter_succcess != prev_iter_success:
                        Discret_step *= 0.5  # reduce the step
                prev_iter_success = this_iter_succcess
                if this_iter_succcess:  # increase discretionary spend
                   discretionary_mult += Discret_step
                else:  # decrease discretionary spend
                   discretionary_mult -= Discret_step
                goals_df = mc_ut.adjust_goals(initial_goals_df, discretionary_mult)
        iter_cnt += 1
    # Repeat final results
    logger.info(success_string)

    # Plot the busted ages
    print(f"busted_counter: {busted_counter}")
    busted_for_plot = pd.DataFrame.from_dict(busted_counter, orient="index")
    Busted_title = "Count of Busted Ages - ({:,.2f}%)".format(100.0 * nb_bust / run_cnt)
    ut.plot_with_rails(busted_for_plot, title=Busted_title, plt_file=plt_file)

    # Compute & plot deciles for assets
    if run_cnt >= 100:
        final_asset_dict = dict()
        final_asset_dict["Min"] = total_ser.loc[0]
        final_asset_dict["Max"] = total_ser.loc[run_cnt - 1]
        final_asset_dict["Avg"] = total_ser.mean()
        delta = int(run_cnt / 10)
        for idx in range(0, run_cnt, delta):  # Average over the decile
            final_asset_dict[idx] = total_ser.loc[idx : idx + delta].mean()
        dict_out = {k: to_dollar(v) for k, v in final_asset_dict.items()}
        logger.info("Final Asset Deciles: ")
        logger.info(str(dict_out))
        final_for_plot = pd.Series([final_asset_dict[idx * delta] for idx in range(0, 10)])
        print(f"final_for_plot: {final_for_plot}")
        ut.plot_with_rails(final_for_plot, title="Decile Results", rails=True, dollar=True, plt_file=plt_file,)
    else:  # not enough values
        logger.info(str(total_ser))

    # Save critical data
    with pd.ExcelWriter(xl_file) as xl_writer:
        goals_df.to_excel(xl_writer, sheet_name="Goals", float_format="%.2f", header=True)
        cashflow_df.to_excel(xl_writer, sheet_name="Cashflow", float_format="%.2f", header=True)
        if run_cnt <= Max_run_to_save:  #
                assets_at_end.to_excel(xl_writer, sheet_name="Iterations", float_format="%.2f", header=True)

    # Wrap up
    outf.close()
    plt_file.close()
    end_time = dt.datetime.now()
    logger.debug("\nEnd: {}".format(str(end_time)))
    logger.debug("Run Time: {}\n".format(str(end_time - start_time)))
    return


if __name__ == "__main__":
    # bug fix for multiprocessing
    set_start_method("forkserver")  # from multiprocessing

    main(sys.argv)
    exit(0)

def main(cmd_line: [str]):
    """Main entry point for MonteCarlo Multi.
    processor_kill_flag: if True, async processes will be killed by the cleanup function
    """
    processor = MonteCarloProcessor(cmd_line)
    processor_kill_flag = False
    exit_code = 0
    # Start the timer for the entire program
    start_time = dt.datetime.now()
    try:
        processor.run()
        logger.info(f"Processing completed")
    except KeyboardInterrupt:
        logger.info("\nKeyboard interrupt received. Cleaning up...")
        # Cancel all async tasks
        processor_kill_flag = True
        exit_code = 1
    except Exception as e:
        logger.info("\nError: {e}")
        # dump stack trace
        logger.error(traceback.format_exc())
        logger.error("\n----\n")
        processor_kill_flag = True
        exit_code = -2
    finally:
        # Only call cleanup if there was an exception or interrupt
        if processor_kill_flag:
            try:
                logger.info(f"Starting final cleanup - kill_flag: {processor_kill_flag}")
                await processor.cleanup(processor_kill_flag)
            except Exception as cleanup_error:
                logger.error(f"Error during final cleanup: {cleanup_error}")
    end_time = dt.datetime.now()
    logger.info(f'End: {str(end_time)} -- Run Time: {str(end_time - start_time)}\n')
    sys.exit(exit_code)

if __name__ == "__main__":
    asyncio.run(main(sys.argv[1:]))
